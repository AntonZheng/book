# Using Remote Server {#remote-server}

Sooner-or-later you are in a situation where you have to work on
a **distant networked computer**.  There may be many reasons, either your
laptop is simply to meany for certain tasks, or certain data is not
allowed to be taken out from there, or you are expected to use the
same computer as your teammates.  The server may be a standalone box
located somewhere in yout employers server room, but it may also be a
virtual maching in cloud, such as Amazon EC2.  You may also want to
set up your own server.


## Server Setup

There are many ways one can set up a distant machine.  It may be
windows or linux (or any of the other unixes).  It may or may not have
graphical user interface (GUI) installed or otherwise accessible (many
unix programs can display nice windows on your laptop while still
running on the server).  It may or may not have RStudio made
available over web browser.  Here we discuss the most barebone setup
with no access to GUI and now web access to RStudio.

This is a fairly common setup, in particular when dealing with
sensitive data or organizations where computer skills or sysadmin's
time is limited.


## Connecting to the Remote Server

The most common way to connect to remote server is via _ssh_.  ssh
stands for "secure shell" and means that both login and all
communication with the server is encrypted.  The command to connect to
the server is
```bash
ssh myserver.somewhere.com
```
The remote server asks for your password and opens remote shell
connection.  It is most likely a similar bash-shell as you are using
on your computer but most likely you see a different prompt, one that
contains the server's name.  You may also see some login
messages.   Now all the commands you are issuing are
running on the remote machine.  So `pwd` shows you your working
directory on the server, which in general is not the same as on the
local machine, and `ls` shows the files on the server, not on your
laptop.  Now you can use `mkdir` to create the project folder on the
server. 

By default, ssh attempts to login with you local username.  If your
username on the server differs, you want to add it to the ssh command:
```bash
ssh username@myserver.somewhere.com
```

## copying files

Before you can start running R scripts on the server, you have to get
these copied over.  There are several possibilities.

### scp

The most universal approach is `scp`, secure copy.  It works in many
ways in the same way as `cp` for the local files, just `scp` can copy
files between your machine and a remote computer.  Under the hood it uses ssh
connection, just like `ssh` command itself.  It syntax is rather
similar to that of `cp`:
```bash
scp user1@host1:file1 user2@host2:file2
```
This copies "file1" from the server "host1" under username "user1" to
the other server.  It asks for passwords as needed.  the "host" part
of the file must be understood as the full hostname including dots,
such as "hyak.washington.edu".  "file" is the full path to file,
relative to home folder, such as "info201/cool_script.R".  When
accessing local files, you may omit the "user@host:" part.  So, for
instance, in order to copy your "cool\_script.R" from folder "info201"
on the Desktop of your laptop to the folder "scripts" on your home
folder on the server, you may issue
```bash
scp Desktop/info201/cool_script.R myusername@server.ischool.edu:scripts/
```
Note that exactly as `cp`, you may omit the destination file name if
the destination is a directory: it simply copies the file into that
directory while preserving it's name.

After running your script, you may want to copy your result--the file
"figure.pdf" back to your laptop.  This can be done with
```bash
scp myusername@server.ischool.edu:scripts/figure.pdf Desktop/info201/
```
As above, this copies a file from the given directory, and drops it
into the "info201" folder on your Desktop.


### rsync

`rsync` is a more modern approach to `scp`.  It works in many way
exactly like `scp`, just is is smart enough to understand which files
are updated, and only copy the updated parts of the files.  It is the
recommended way to go if dealing with small updates in large files.
It's syntax is rather similar to that of `scp`.  To copy a "file" to the
remote server as "file2", we do
```
rsync file user2@host2:file2
```
and in order to copy a "file1" from server as local "file":
```
rsync file user1@host1:file1 file
```
(rsync cannot copy between two remote computers).  I also recommend to
explore some of the many options, for instance `-v` (verbose) reports
what it's doing.
The example above with your code and figure might now look like that:
```bash
rsync -v Desktop/info201/cool_script.R myusername@server.ischool.edu:scripts/
# now run the script on the remote machine
rsync -v myusername@server.ischool.edu:scripts/figure.pdf Desktop/info201/
```

Maybe the easiest way to copy your files is to copy the whole
directories.  For instance, instead of the code above, you can do
```bash
rsync -v Desktop/info201/* myusername@server.ischool.edu:scripts/
# now run the script on the remote machine
rsync -v myusername@server.ischool.edu:scripts/* Desktop/info201/
```
Here `*` means _all files in this directory_.  Hence, now, instead of
copying the files individually between the computers, we just copy all
of them.  Even better, we actually do not copy but just update.  Huge
files that do not change do not take any bandwidth.


### Graphical Frontends

Instead on relying on command line tools, one can also use graphical
front-ends.  For instance, "WinSCP" is a nice Norton-Commander-Style
frontend for copying files between local and remote machine over scp
for Windows.  It provides a split window representing files on the
local and remote end, and one can move, copy-and-paste and interact
with mouse in these areas.  On Mac you may take a look at
"Cyberduck". 


### remote editing

Besides copying your files, many text editors also offer "remote
editing" option.  From the user perspective this looks as if directly
working on the remote server's hard disk.  Under the hood, the files
are copied back and forth with scp, rsync or one of their friends.
Emacs and vi do it out-of-the box, VSCode, Atom and sublime requirea
plugin.  AFAIK it is not possible with RStudio.

It is also possible to mount (attach) the harddisk of the remote
server to your laptop as if it were a local disk.  Again, scp and
friends will do the hard work under the hood.


## Rscript

## ssh keys, .ssh/config



Once you've added everyone to the GitHub repository, **each team member** will need to **`clone`** the repository to their local machines to work on the code individually. Collaborators can then `push` any changes they make to the central repository, and `pull` and changes made by others. Because multiple members will be contributing to the _same repositiory_, it's important to ensure that you are working on the most up-to-date version of the code. This means that you will regularly have to **pull in changes** from GitHub that your team members may have committed. As a result, we suggest that you have a workflow that looks like this:

```bash
# Begin your work session by pulling in changes from GitHub
git pull origin master

# If necessary, resolve any merge conflicts and commit them
git add .
git commit -m "Merge in changes from GitHub"

# Do your work, then add, commit and push
git add .
git commit -m "Make progress on feature X"
git push origin master
```

Note, if someone pushes a commit to GitHub _before you push your changes_, you'll need to integrate those into your code (and test them!) before pushing up to GitHub. While working on a single `master` branch in this fashion is possible, you'll encounter fewer conflicts if you use a dedicated **feature branch** for each developer or feature you're working on.

## Feature Branch Workflow
The Feature Branch Workflow is a natural extension of the Centralized Workflow that enhances the model by defining specific _branches_ for different pieces of development (still with one centralized repository). The core idea behind the Feature Branch Workflow is that all development should take place on a dedicated **feature branch**, rather than on the `master` branch. This allows for different people to work on different branches without disturbing the main codebase. For example, you might have one branch `visualization` that focuses on adding a complex visualization, or another `experimental-analysis` that tries a bold new approach to processing the data. Each branch is based on a _feature_ (capability or part) of the project, not a particular person: a single developer could be working on multiple feature branches.

The idea is that the `master` branch _always_ contains "production-level" code: valid, completely working code that you could deploy or publish (read: give to your boss or teacher) at a whim. All feature branches branch off of `master`, and are allowed to contain temporary or even broken code (since they are still in development). This way there is always a "working" (if incomplete) copy of the code (`master`), and development can be kept isolated and considered independent of the whole. This is similar to the example with the `experiment` branch above.

The workflow thus works like this:

1. Ada decides to add a new feature or part to the code. She creates a new feature branch off of `master`:

    ```bash
    git checkout master
    git checkout -b adas-feature
    ```

2. Ada does some work on this feature

    ```bash
    # work is done outside of terminal

    git add .
    git commit -m "Adds progress on feature"
    ```

3. Ada takes a break, pushing her changes to GitHub

    ```bash
    git push -u origin adas-feature
    ```

4. After talking to Ada, Bebe decides to help finish up the feature. She checks out the branch and makes some changes, then pushes them back to GitHub

    ```bash
    # fetch will "download" commits from GitHub, without merging them
    git fetch origin
    git checkout adas-feature

    # work is on adas-feature done outside of terminal

    git add .
    git commit -m "Adds more progress on feature"
    git push origin adas-feature
    ```

5. Ada downloads Bebe's changes

    ```bash
    git pull origin adas-feature
    ```

6. Ada decides the feature is finished, and _merges_ it back into `master`. But first, she makes sure she has the latest version of the `master` code to integrate her changes with

    ```bash
    git checkout master  # switch to master
    git pull origin master  # download any changes

    git merge adas-feature  # merge the feature into the master branch
    # fix any merge conflicts!!

    git push origin master  # upload the updated code to master
    ```

7. And now that the feature has been successfully added to the project, Ada can delete the feature branch (using `git branch -d branch_name`). See also [here](http://stackoverflow.com/questions/2003505/how-to-delete-a-git-branch-both-locally-and-remotely).

This kind of workflow is very common and effective for supporting collaboration. Note that as projects get large, you may need to start being more organized about how and when you create feature branches. For example, the [**Git Flow**](http://nvie.com/posts/a-successful-git-branching-model/) model organizes feature branches around product releases, and is often a starting point for large collaborative projects.

## Forking Workflow
The Forking Workflow takes a **fundamentally different approach** to collaboration than the Centralized and Feature Branch workflows. Rather than having a single remote, each developer will have **their own repository** on GitHub that is _forked_ from the original repository. As discussed in the [introductory GitHub Chapter](#git-basics), a developer can create their own remote repositry from an existing project by _forking_ it on GitHub. This allows the individual to make changes (and contribute to) the project. However, we have not yet discussed how those changes can be integrated into the original code base. GitHub offers a feature called [**pull requests**](https://help.github.com/articles/creating-a-pull-request/) by which you can merge two remote branches (that is: `merge` two branches that are on GitHub). A **pull request** is a request for the changes from one branch to be pulled (merged) into another.

### Pull Requests
Pull requests are primarily used to let teams of developers _collaborate_&mdash;one developer can send a request "hey, can you integrate my changes?" to another. The second developer can perform a **code review**: reviewing the proposed changes and making comments or asking for corrections to anything they find problematic. Once the changes are improved, the pull request can be **accepted** and the changes merged into the target branch. This process is how programmers collaborate on _open-source software_ (such as R libraries like `dplyr`): a developer can _fork_ an existing professional project, make changes to that fork, and then send a pull request back to the original developer asking them to merge in changes ("will you include my changes in your branch/version of the code?").

<p class="alert alert-warning">Pull requests should only be used when doing collaboration using remote branches! Local branches should be `merged` locally using the command-line, not GitHub's pull request feature.</p>

In order to issue a pull request, both branches you wish to merge will need to be `pushed` to GitHub (whether they are in the same repo or in forks). To issue the pull request, navigate to your repository on GitHub's web portal and choose the **New Pull Request** button (it is next to the drop-down that lets you view different branches).

In the next page, you will need to specify which branches you wish to merge. The **base** branch is the one you want to merge _into_ (often `master`), and the **head** branch (labeled "compare") is the branch with the new changes you want to merge (often a feature branch; see below).

Add a title and description for your pull request. These should follow the format for git commit messages. Finally, click the **Create pull request** button to finish creating the pull request.

<p class="alert alert-info">Important! The pull request is a request to merge two branches, not to merge a specific set of commits. This means that you can _push more commits_ to the head/merge-from branch, and they will automatically be included in the pull request&mdash;the request is always "up-to-date" with whatever commits are on the (remote) branch.</p>

You can view all pull requests (including those that have been accepted) through the **Pull Requests** tab at the top of the repo's web portal. This is where you can go to see comments that have been left by the reviewer.

If someone sends you a pull request (e.g., another developer on your team), you can [accept that pull request](https://help.github.com/articles/merging-a-pull-request/) through GitHub's web portal. If the branches can be merged without a conflict, you can do this simply by hitting the **Merge pull request** button. However, if GitHub detects that a conflict may occur, you will need to [pull down the branches and merge them locally](https://help.github.com/articles/checking-out-pull-requests-locally).

<p class="alert alert-warning">It is best practice to _never_ accept your own pull requests! If you don't need any collaboration, just merge the branches locally.</p>

Note that when you merge a pull request via the GitHub web site, the merge is done entirely on the server. Your local repo will not yet have those changes, and so you will need to use `git pull` to download the updates to an appropriate branch.

## Resources {-}
- [Atlassian Git Workflows Tutorial](https://www.atlassian.com/git/tutorials/comparing-workflows)
